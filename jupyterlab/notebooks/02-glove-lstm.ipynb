{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f0b6ec4-5cb7-4e74-9934-93ef1cc8ac82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df584ee1-131e-4fb6-adea-73820d003a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                            message\n",
       "0    ham  Go until jurong point, crazy.. Available only ...\n",
       "1    ham                      Ok lar... Joking wif u oni...\n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3    ham  U dun say so early hor... U c already then say...\n",
       "4    ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILE_PATH = \"../../data/spam.csv\"\n",
    "\n",
    "df = pd.read_csv(FILE_PATH, encoding=\"latin-1\")\n",
    "\n",
    "df = df.dropna(how=\"any\", axis=1)\n",
    "\n",
    "df = df.rename(columns={ \"v1\": \"target\", \"v2\": \"message\" })\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41924413-9d6e-40c5-a99a-5f42d61d3feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>message</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in  a wkly comp to win fa cup final...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                            message  \\\n",
       "0    ham  Go until jurong point, crazy.. Available only ...   \n",
       "1    ham                      Ok lar... Joking wif u oni...   \n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3    ham  U dun say so early hor... U c already then say...   \n",
       "4    ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                           processed  \n",
       "0  go until jurong point crazy available only in ...  \n",
       "1                            ok lar joking wif u oni  \n",
       "2  free entry in  a wkly comp to win fa cup final...  \n",
       "3        u dun say so early hor u c already then say  \n",
       "4  nah i dont think he goes to usf he lives aroun...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "def process_df(df):\n",
    "    df['processed'] = df['message'].apply(clean_text)\n",
    "    return df\n",
    "\n",
    "df = process_df(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3094050-e549-413f-89bb-7a46105a1fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>message</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazy available bugis n great ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joking wif oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry  wkly comp win fa cup final tkts  m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>dun say early hor already say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah dont think goes usf lives around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                            message  \\\n",
       "0    ham  Go until jurong point, crazy.. Available only ...   \n",
       "1    ham                      Ok lar... Joking wif u oni...   \n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3    ham  U dun say so early hor... U c already then say...   \n",
       "4    ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                           processed  \n",
       "0  go jurong point crazy available bugis n great ...  \n",
       "1                              ok lar joking wif oni  \n",
       "2  free entry  wkly comp win fa cup final tkts  m...  \n",
       "3                      dun say early hor already say  \n",
       "4        nah dont think goes usf lives around though  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "more_stopwords = ['u', 'im', 'c']\n",
    "stop_words = stop_words + more_stopwords\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = ' '.join(word for word in text.split(' ') if word not in stop_words)\n",
    "    return text\n",
    "    \n",
    "df['processed'] = df['processed'].apply(remove_stopwords)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1a947b94-053a-4f80-aca3-087c97cccb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>message</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joke wif oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entri  wkli comp win fa cup final tkts  m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>dun say earli hor alreadi say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah dont think goe usf live around though</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  target                                            message  \\\n",
       "0    ham  Go until jurong point, crazy.. Available only ...   \n",
       "1    ham                      Ok lar... Joking wif u oni...   \n",
       "2   spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3    ham  U dun say so early hor... U c already then say...   \n",
       "4    ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                           processed  \n",
       "0  go jurong point crazi avail bugi n great world...  \n",
       "1                                ok lar joke wif oni  \n",
       "2  free entri  wkli comp win fa cup final tkts  m...  \n",
       "3                      dun say earli hor alreadi say  \n",
       "4          nah dont think goe usf live around though  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = nltk.SnowballStemmer(\"english\")\n",
    "\n",
    "def stemm_text(text):\n",
    "    text = ' '.join(stemmer.stem(word) for word in text.split(' '))\n",
    "    return text\n",
    "\n",
    "df['processed'] = df['processed'].apply(stemm_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47c0a588-a298-47d6-aa08-d63c0d63948d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>message</th>\n",
       "      <th>processed</th>\n",
       "      <th>target_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>go jurong point crazi avail bugi n great world...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>ok lar joke wif oni</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entri  wkli comp win fa cup final tkts  m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>dun say earli hor alreadi say</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah dont think goe usf live around though</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                            message  \\\n",
       "0       0  Go until jurong point, crazy.. Available only ...   \n",
       "1       0                      Ok lar... Joking wif u oni...   \n",
       "2       0  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3       0  U dun say so early hor... U c already then say...   \n",
       "4       0  Nah I don't think he goes to usf, he lives aro...   \n",
       "\n",
       "                                           processed  target_encoded  \n",
       "0  go jurong point crazi avail bugi n great world...               0  \n",
       "1                                ok lar joke wif oni               0  \n",
       "2  free entri  wkli comp win fa cup final tkts  m...               1  \n",
       "3                      dun say earli hor alreadi say               0  \n",
       "4          nah dont think goe usf live around though               0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'] = df['target_encoded'].apply(lambda x: 1 if x == \"spam\" else 0)\n",
    "df.head()\n",
    "\n",
    "# To be replaced with spam 1, ham 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3defbdaa-17ec-46dc-b280-30837d07f2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['processed']\n",
    "target = df['target_encoded']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4685db72-78fd-4319-b560-f1731e5f123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    texts, \n",
    "    target, \n",
    "    test_size=0.25,\n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b0eb575-a5d0-4122-9212-70f33d83fe0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4179"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6fd8aceb-59a4-4c11-bdaf-c97317bb65e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5746"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "word_tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "vocab_length = len(word_tokenizer.word_index) + 1\n",
    "vocab_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "38fcc1ab-b442-45fb-ab8a-7558200f91c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8c67991-4dc7-4fd0-8083-9065c4d7e61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {}\n",
    "metadata[\"vocabulary_size\"] = vocab_length\n",
    "metadata[\"max_length\"] = max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70bd897f-f539-4c17-8b25-312e2bdb8839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.57832998, -0.0036551 ,  0.34658   , ...,  0.070204  ,\n",
       "         0.44509   ,  0.24147999],\n",
       "       [-0.078894  ,  0.46160001,  0.57779002, ...,  0.26352   ,\n",
       "         0.59397   ,  0.26741001],\n",
       "       ...,\n",
       "       [-0.53434002,  0.096645  ,  0.13808   , ...,  0.12309   ,\n",
       "         0.69825   ,  0.88173997],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dictionary = dict()\n",
    "embedding_dim = 100\n",
    "\n",
    "# Load GloVe 100D embeddings\n",
    "with open('./glove.6B.100d.txt') as fp:\n",
    "    for line in fp.readlines():\n",
    "        records = line.split()\n",
    "        word = records[0]\n",
    "        vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
    "        embeddings_dictionary [word] = vector_dimensions\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_length, embedding_dim))\n",
    "\n",
    "for word, index in word_tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector\n",
    "        \n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a9a631c-39cc-436a-a9ff-8525bafba002",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5746, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0721f9c9-76dd-4b4c-93ad-be1d7889dbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b38c355-5cf8-4042-b8cc-88688441265f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0].split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "175978e4-f779-4ca4-bb3e-c493d0957b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4179, 80)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def embed(corpus): \n",
    "    return word_tokenizer.texts_to_sequences(corpus)\n",
    "\n",
    "train_padded_sentences = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    embed(X_train), \n",
    "    max_length, \n",
    "    padding='post'\n",
    ")\n",
    "\n",
    "train_padded_sentences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "093a760b-fba0-40eb-b0f1-3ed17b4c5c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "word_index = {}\n",
    "for word, index in word_tokenizer.word_index.items():\n",
    "    word_index[word] = index\n",
    "\n",
    "metadata[\"word_index\"] = word_index\n",
    "\n",
    "with open(\"metadata.json\", \"w\") as f:\n",
    "    json.dump(metadata, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8584a102-6516-4400-bb8e-0fc5371a1b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, 80, 100)           574600    \n",
      "                                                                 \n",
      " bidirectional_4 (Bidirectio  (None, 80, 160)          115840    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " global_max_pooling1d_4 (Glo  (None, 160)              0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 160)              640       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 160)               0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 80)                12880     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 80)                6480      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 80)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 81        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 710,521\n",
      "Trainable params: 135,601\n",
      "Non-trainable params: 574,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def glove_lstm(max_length):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    model.add(tf.keras.layers.Input((max_length,)))\n",
    "    \n",
    "    # model.add(tf.keras.layers.Embedding(\n",
    "    #     input_dim=embedding_matrix.shape[0], \n",
    "    #     output_dim=embedding_matrix.shape[1], \n",
    "    #     weights = [embedding_matrix], \n",
    "    #     input_length=length_long_sentence\n",
    "    # ))\n",
    "    \n",
    "    model.add(tf.keras.layers.Embedding(\n",
    "        input_dim=vocab_length,\n",
    "        output_dim=embedding_dim,\n",
    "        input_length=max_length,\n",
    "        weights = [embedding_matrix],\n",
    "        trainable=False\n",
    "    ))\n",
    "    \n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(\n",
    "        max_length, \n",
    "        return_sequences = True, \n",
    "        recurrent_dropout=0.2\n",
    "    )))\n",
    "    \n",
    "    model.add(tf.keras.layers.GlobalMaxPool1D())\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(max_length, activation = \"relu\"))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(max_length, activation = \"relu\"))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1, activation = 'sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = glove_lstm(max_length)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25f54504-f75b-4990-8245-162ace23217b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_padded_sentences = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    embed(X_test), \n",
    "    max_length, \n",
    "    padding='post'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8442482a-292e-4357-8551-ceadb77367f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "131/131 [==============================] - 29s 186ms/step - loss: 0.3453 - accuracy: 0.8703 - val_loss: 0.3421 - val_accuracy: 0.9476\n",
      "Epoch 2/7\n",
      "131/131 [==============================] - 27s 209ms/step - loss: 0.2055 - accuracy: 0.9337 - val_loss: 0.2023 - val_accuracy: 0.9612\n",
      "Epoch 3/7\n",
      "131/131 [==============================] - 27s 202ms/step - loss: 0.1640 - accuracy: 0.9495 - val_loss: 0.5470 - val_accuracy: 0.7042\n",
      "Epoch 4/7\n",
      "131/131 [==============================] - 52s 396ms/step - loss: 0.1529 - accuracy: 0.9524 - val_loss: 1.6021 - val_accuracy: 0.8808\n",
      "Epoch 5/7\n",
      "131/131 [==============================] - 48s 363ms/step - loss: 0.1344 - accuracy: 0.9569 - val_loss: 0.1868 - val_accuracy: 0.9641\n",
      "Epoch 6/7\n",
      "131/131 [==============================] - 39s 294ms/step - loss: 0.1000 - accuracy: 0.9672 - val_loss: 0.1293 - val_accuracy: 0.9698\n",
      "Epoch 7/7\n",
      "131/131 [==============================] - 43s 330ms/step - loss: 0.0974 - accuracy: 0.9675 - val_loss: 0.1438 - val_accuracy: 0.9698\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_padded_sentences, \n",
    "    y_train, \n",
    "    epochs = 7,\n",
    "    batch_size = 32,\n",
    "    validation_data = (test_padded_sentences, y_test),\n",
    "    verbose = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fc713b61-e56a-4961-a809-57cde2abce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: lstm_glove/assets\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p saved_model\n",
    "model.save('lstm_glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "97ac12a9-d2ea-43b4-8a35-8ac7169f4fe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-14 15:43:10.019478: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-14 15:43:10.020736: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-06-14 15:43:13.781874: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-06-14 15:43:13.782011: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-14 15:43:13.782131: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ada8cfd194fc): /proc/driver/nvidia/version does not exist\n",
      "2022-06-14 15:43:13.782510: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-14 15:43:16.691043: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\n",
      "2022-06-14 15:43:16.692388: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "Writing weight file ./tfjs_lstm_glove/model.json...\n"
     ]
    }
   ],
   "source": [
    "!tensorflowjs_converter --input_format=tf_saved_model --output_format tfjs_graph_model --control_flow_v2=true ./lstm_glove ./tfjs_lstm_glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "35953b34-5b83-462c-beb1-300758f51400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1000.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.zeros((1,80))\n",
    "test[0][0] = 1000\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "18986c7c-32c6-424b-aff1-7429965ffb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.8707024e-05]], dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6fa93-7452-40e6-88b4-91e8113eef5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m93",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m93"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
